{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a045bd5-5f8b-4f9f-80fa-f781753ad535",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lyonia UV/Vis Parser and Merger\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set your working directory to the folder with your files\n",
    "DATA_DIR = Path(\"~/Documents/ScienceProjects/2025/LyoniaUV\").expanduser()\n",
    "TXT_DIR = DATA_DIR  # assuming all .txt files are in this folder\n",
    "SAMPLE_INFO_FILE = DATA_DIR / \"UVTrans_Lyonia_13May2025_JW.csv\"  # update if name differs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0974d16-4fac-4bfc-9276-cd20fe8f456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 1: Parse each UV/Vis text file ---\n",
    "def parse_txt_file(file_path):\n",
    "    with open(file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Find where spectral data begins\n",
    "    start_idx = next(i for i, line in enumerate(lines) if '>>>>>Begin Spectral Data<<<<<' in line) + 1\n",
    "    spectral_data = []\n",
    "\n",
    "    for line in lines[start_idx:]:\n",
    "        if line.strip() == \"\":\n",
    "            continue\n",
    "        try:\n",
    "            wavelength, value = map(float, line.strip().split())\n",
    "            spectral_data.append((wavelength, value))\n",
    "        except ValueError:\n",
    "            continue  # skip bad lines\n",
    "\n",
    "    df = pd.DataFrame(spectral_data, columns=['Wavelength', 'Value'])\n",
    "    df['Filename'] = file_path.name\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f558abd-c3d6-4a23-a1b7-20d513950f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 2: Load metadata spreadsheet ---\n",
    "metadata = pd.read_csv(SAMPLE_INFO_FILE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ccfa9935-647a-411b-9af3-26a0a7cf776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 3: Fill missing prefixes (for long-suffix files) ---\n",
    "metadata['File_prefix'] = metadata['File_prefix'].fillna(\"WindowProjectSample\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "451da17d-18f8-4499-ad5e-5c43938576db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 4: Build 'FilenameBase' column ---\n",
    "def build_filename_base(row):\n",
    "    try:\n",
    "        num = int(float(str(row['filename']).split('_')[0]))\n",
    "    except:\n",
    "        return None\n",
    "    prefix = row['File_prefix']\n",
    "    return f\"{prefix}_Transmission__{num}__\"\n",
    "\n",
    "metadata['FilenameBase'] = metadata.apply(build_filename_base, axis=1)\n",
    "\n",
    "# Create a lookup dict for exact or prefix match\n",
    "filename_lookup = {fb: md_row for fb, md_row in metadata.set_index('FilenameBase').iterrows() if fb}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e95a585-7e9a-459d-bc9e-2673e25740f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 5: Parse all txt files ---\n",
    "txt_files = list(TXT_DIR.glob(\"*.txt\"))\n",
    "spectra = pd.concat([parse_txt_file(f) for f in txt_files], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3414132-8a51-4322-9efb-100eb6a7636b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 6: Match metadata ---\n",
    "def match_metadata(filename):\n",
    "    if filename in filename_lookup:\n",
    "        return filename_lookup[filename]\n",
    "    for base, row in filename_lookup.items():\n",
    "        if base and base in filename:\n",
    "            return row\n",
    "    return pd.Series([None]*len(metadata.columns), index=metadata.columns)\n",
    "\n",
    "# Apply matching\n",
    "meta_cols = metadata.columns.tolist()\n",
    "spectra_with_meta = spectra.copy()\n",
    "spectra_with_meta[meta_cols] = spectra_with_meta['Filename'].apply(match_metadata)\n",
    "\n",
    "# Drop rows that didn't match metadata\n",
    "merged = spectra_with_meta.dropna(subset=['plant', 'species'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31882326-e9a4-47b8-8c65-8706b5244db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Step 7: Save merged data ---\n",
    "merged.to_csv(DATA_DIR / \"merged_uvvis_data.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f73a89c-2d74-4d56-835b-0e582c0370a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unmatched files:\n",
      "WindowProjectSample3_Transmission__52__00052.txt\n",
      "\n",
      "Total unmatched files: 1\n"
     ]
    }
   ],
   "source": [
    "# Identify all unmatched files (no metadata joined)\n",
    "unmatched = spectra_with_meta[spectra_with_meta['plant'].isna()]\n",
    "\n",
    "# Show just the unique filenames\n",
    "unmatched_files = unmatched['Filename'].unique()\n",
    "\n",
    "# Print them\n",
    "print(\"Unmatched files:\")\n",
    "for fname in unmatched_files:\n",
    "    print(fname)\n",
    "\n",
    "# Optional: How many\n",
    "print(f\"\\nTotal unmatched files: {len(unmatched_files)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
